{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Cb0M4oc7YIV0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#import keras\n",
        "from keras.layers import Dense, Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "#from keras.layers import Activation, Dense, Input\n",
        "#from keras.layers import , Flatten\n",
        "#from keras.layers import Reshape, Conv2DTranspose\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "#from PIL import Image\n",
        "#from skimage.transform import resize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Funciones útiles\n",
        "\n",
        "def noise_data(noise_location, noise_strength):\n",
        "  (x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "  image_size = x_train.shape[1]\n",
        "  x_train = np.reshape(x_train, [-1, 28,28, 1])/255.0\n",
        "  x_test = np.reshape(x_test, [-1, 28,28, 1])/255.0\n",
        "  input_shape = (28,28, 1)\n",
        "\n",
        "  noise = np.random.normal(loc=noise_location, scale=noise_strength, size=x_train.shape)\n",
        "  x_train_noisy = x_train + noise\n",
        "  noise = np.random.normal(loc=noise_location, scale=noise_strength, size=x_test.shape)\n",
        "  x_test_noisy = x_test + noise\n",
        "\n",
        "  x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "  x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
        "  return x_train,x_train_noisy,x_test,x_test_noisy,input_shape\n",
        "\n",
        "def show_as_single_image(imgs,image_shape=None):\n",
        "  if image_shape is None:\n",
        "    n,h,w,c=imgs.shape\n",
        "  else:\n",
        "    h,w=image_shape\n",
        "    n,c=imgs.shape\n",
        "  imgs = imgs.reshape((n, h,w))\n",
        "  imgs = imgs.swapaxes(1,2).reshape((n*w, h)).swapaxes(0,1)\n",
        "  imgs = (imgs * 255).astype(np.uint8)\n",
        "\n",
        "  plt.figure(figsize=(1*8,n*8),dpi=100)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(imgs, interpolation='none', cmap='gray')\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "5poLSDK3YgN5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga de datos\n",
        "\n",
        "noise_location=0.3\n",
        "noise_strength=0.2\n",
        "x_train,x_train_noisy,x_test,x_test_noisy,input_shape = noise_data(noise_location,noise_strength)"
      ],
      "metadata": {
        "id": "xoFQ-TxSkw7g"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualización de las imágenes originales y sus versiones ruidosas\n",
        "\n",
        "num=10 # cantidad de imágenes a visualizar\n",
        "print(\"Originales\")\n",
        "show_as_single_image(x_test[:num])\n",
        "print(\"Ruidosas\")\n",
        "show_as_single_image(x_test_noisy[:num])"
      ],
      "metadata": {
        "id": "JBTzcmx8k94-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ConvolutionalAutoencoder(input_shape):\n",
        "  filters = 32\n",
        "\n",
        "  def generate_encoder():\n",
        "    encoder_input = Input(shape=input_shape, name='encoder_input')\n",
        "\n",
        "    x = Conv2D(filters, (3, 3), activation='relu', padding='same')(encoder_input)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = Conv2D(filters//2, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = Conv2D(filters//2, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    encoded_shape = K.int_shape(x)[1:]\n",
        "\n",
        "    encoder = Model(encoder_input, x, name='encoder')\n",
        "    return encoder,encoder_input,encoded_shape\n",
        "\n",
        "  def generate_decoder(encoded_shape):\n",
        "    latent_input = Input(shape=encoded_shape, name='decoder_input')\n",
        "\n",
        "    x = Conv2D(filters//2, (3, 3), activation='relu', padding='same')(latent_input)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(filters//2, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(filters, (3, 3), activation='relu')(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    decoder = Model(latent_input, x, name='decoder')\n",
        "    return decoder,latent_input\n",
        "\n",
        "  encoder,encoder_input,encoded_shape = generate_encoder()\n",
        "  decoder,latent_input = generate_decoder(encoded_shape)\n",
        "  autoencoder = Model(encoder_input, decoder(encoder(encoder_input)), name='autoencoder')\n",
        "  return autoencoder,encoder,decoder,encoded_shape\n",
        "\n",
        "autoencoder,encoder,decoder,encoded_shape=ConvolutionalAutoencoder(input_shape)\n",
        "autoencoder.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "print(autoencoder.summary())\n",
        "print(encoder.summary())\n",
        "print(decoder.summary())"
      ],
      "metadata": {
        "id": "iHTl51Vmmu5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar el entrenamiento\n",
        "\n",
        "epochs=1\n",
        "batch_size = 32\n",
        "autoencoder.fit(x_train_noisy, x_train, validation_data=(x_test_noisy,x_test), epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "YeqAQMy6m0PN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar la predicción\n",
        "\n",
        "x_decoded = autoencoder.predict(x_test_noisy)"
      ],
      "metadata": {
        "id": "SLcgZSdenCbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualización de las imágenes originales, sus versiones ruidosas y sus respectivas reconstrucciones\n",
        "\n",
        "num=10 # cantidad de imágenes a visualizar\n",
        "print(\"Originales\")\n",
        "show_as_single_image(x_test[:num])\n",
        "print(\"Ruidosas\")\n",
        "show_as_single_image(x_test_noisy[:num])\n",
        "print(\"Restauradas\")\n",
        "show_as_single_image(x_decoded[:num])"
      ],
      "metadata": {
        "id": "yZopNyuGnHXV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}