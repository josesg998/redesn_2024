{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import os\n","import numpy as np\n","import tqdm\n","import matplotlib.pyplot as plt\n","\n","from keras.layers import Input\n","from keras.models import Model, Sequential\n","from keras.layers.core import Reshape, Dense, Dropout, Flatten\n","from keras.layers import LeakyReLU\n","from keras.layers.convolutional import Convolution2D, UpSampling2D\n","from keras.layers import BatchNormalization\n","from keras.datasets import mnist\n","from keras.optimizers import Adam\n","from keras import backend as K\n","from keras import initializers"],"metadata":{"id":"WUvrqAmlqcgZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Salida determinística (comentar para aleatorizar el entrenamiento)\n","np.random.seed(1000)"],"metadata":{"id":"2ZnizY0zqh-d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Funciones útiles\n","\n","def plot_losses(d_losses,g_losses):\n","    plt.figure(figsize=(10, 8))\n","    plt.plot(d_losses, label='Discriminitive loss')\n","    plt.plot(g_losses, label='Generative loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","# Dibujar imagenes generadas\n","def plot_images(epoch, examples=36, dim=(6, 6), figsize=(5, 5)):\n","    noise = np.random.normal(0, 1, size=[examples, latent_dim])\n","    generated_images = generator.predict(noise)\n","    generated_images = generated_images.reshape(examples, 28, 28)\n","\n","    plt.figure(figsize=figsize)\n","    for i in range(generated_images.shape[0]):\n","        plt.subplot(dim[0], dim[1], i+1)\n","        plt.imshow(generated_images[i], interpolation='nearest', cmap='gray')\n","        plt.axis('off')\n","    plt.suptitle(f\"Epoch {epoch}\")\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"u6o3nT0yrhyl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cargar MNIST (solo x_train)\n","\n","(X_train, _), (_, _) = mnist.load_data()\n","X_train = (X_train.astype(np.float32)/255)-0.5\n","X_train = X_train.reshape(60000, 28,28,1)\n","output_shape=(28,28,1)"],"metadata":{"id":"PRxOh72EqoOF"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z8QquYWUy51U"},"source":["def GAN(latent_dim,output_shape):\n","  adam = Adam(learning_rate=0.0002, beta_1=0.5)\n","\n","  # Red Generadora\n","  generator = Sequential(name=\"generator\")\n","  generator.add(Dense(128, input_dim=latent_dim, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n","  generator.add(LeakyReLU(0.2))\n","  generator.add(Dense(256))\n","  generator.add(LeakyReLU(0.2))\n","  generator.add(Dense(512))\n","  generator.add(LeakyReLU(0.2))\n","  generator.add(Dense(784, activation='tanh'))\n","  generator.add(Reshape(output_shape))\n","\n","  # Red Discriminadora\n","  discriminator = Sequential(name=\"discriminator\")\n","  discriminator.add(Flatten(input_shape=output_shape))\n","  discriminator.add(Dense(1024, input_dim=784, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n","  discriminator.add(LeakyReLU(0.2))\n","  discriminator.add(Dropout(0.3))\n","  discriminator.add(Dense(512))\n","  discriminator.add(LeakyReLU(0.2))\n","  discriminator.add(Dropout(0.3))\n","  discriminator.add(Dense(256))\n","  discriminator.add(LeakyReLU(0.2))\n","  discriminator.add(Dropout(0.3))\n","  discriminator.add(Dense(1, activation='sigmoid'))\n","  discriminator.compile(loss='binary_crossentropy', optimizer=adam)\n","\n","  # No entrenar el discriminador al entrenar todo\n","  discriminator.trainable = False\n","\n","  # Red GAN completa\n","  ganInput = Input(shape=(latent_dim,),name=\"input\")\n","  x = generator(ganInput)\n","  ganOutput = discriminator(x)\n","  gan = Model(inputs=ganInput, outputs=ganOutput,name=\"GAN\")\n","  gan.compile(loss='binary_crossentropy', optimizer=adam)\n","  return gan,discriminator,generator\n","\n","latent_dim = 16\n","gan,discriminator,generator = GAN(latent_dim, output_shape)\n","\n","print(gan.summary())\n","print(generator.summary())\n","print(discriminator.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# entrenar el GAN\n","\n","batch_size = 128\n","epochs = 3\n","\n","batches = X_train.shape[0] // batch_size\n","print( f'Epochs:{epochs}')\n","print( f'Batch size: {batch_size}')\n","print( f'Batches per epoch: {batches}')\n","\n","d_losses = []\n","g_losses = []\n","for e in range(epochs):\n","        for _ in range(batches):\n","            # Generar un vector de valores aleatorios\n","            noise = np.random.normal(0, 1, size=[batch_size, latent_dim])\n","\n","            # Generar imágenes falsas de MNIST en base a ese vector\n","            fake_images_batch = generator.predict(noise)\n","\n","            # Imagenes reales aleatorias\n","            real_images_batch = X_train[np.random.randint(0, X_train.shape[0], size=batch_size)]\n","\n","            # Genero un batch para el discriminador\n","            x_discriminator = np.concatenate([real_images_batch, fake_images_batch])\n","\n","            # Ponemos clase 1 para las imagenes reales  y clase 0 a las imágenes falsas\n","            y_discriminator = np.concatenate([np.ones(batch_size),np.zeros(batch_size)])\n","\n","            # Entrenar discriminador\n","            discriminator.trainable = True\n","\n","            # train_on_batch es un método del modelo de Keras\n","            d_loss = discriminator.train_on_batch(x_discriminator, y_discriminator, verbose = False)\n","            discriminator.trainable = False\n","\n","            # Entrenar generador (entrena toda la red)\n","            noise = np.random.normal(0, 1, size=[batch_size, latent_dim])\n","            y_generator = np.ones(batch_size)\n","\n","            g_loss = gan.train_on_batch(noise, y_generator)\n","\n","        # Guardar losses del ultimo batch\n","        tqdm.tqdm.write( f'Errores: G={g_loss}, D={d_loss}')\n","        d_losses.append(d_loss)\n","        g_losses.append(g_loss)\n","        #dibujar imagenes generadas\n","        if e == 0 or e % 5 == 0:\n","            plot_images(e)\n","\n","plot_losses(d_losses,g_losses)"],"metadata":{"id":"be-Rjkb1ror9"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oASZ-v403TzC"},"source":["# Dibujar imagenes generadas\n","\n","dim=(4, 4)\n","figsize=(5, 5)\n","\n","random_input = np.random.normal(0, 1, size=[dim[0]*dim[1], latent_dim])\n","\n","generated_images = generator.predict(random_input)\n","\n","plt.figure(figsize=figsize)\n","for i in range(generated_images.shape[0]):\n","        plt.subplot(dim[0], dim[1], i+1)\n","        plt.imshow(generated_images[i], interpolation='nearest', cmap='gray')\n","        plt.axis('off')\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]}]}