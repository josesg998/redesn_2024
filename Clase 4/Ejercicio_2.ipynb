{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install -q --upgrade keras-cv"],"metadata":{"id":"bSQztj7qZ6fL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import keras\n","import keras_cv\n","from keras_cv import visualization\n","import numpy as np"],"metadata":{"id":"xm6r3hfkZhHE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cargamos el modelo preentrenado con PASCAL VOC\n","# Más opciones (más modelos) en https://keras.io/api/keras_cv/models/tasks/yolo_v8_detector/#yolov8detector-class\n","\n","pretrained_model_name = \"yolo_v8_m_pascalvoc\"\n","\n","# Estas son las clases del modelo preentrenado\n","class_names = [\"Aeroplane\", \"Bicycle\", \"Bird\", \"Boat\", \"Bottle\", \"Bus\", \"Car\", \"Cat\", \"Chair\",\n","               \"Cow\", \"Dining Table\", \"Dog\", \"Horse\", \"Motorbike\", \"Person\", \"Potted Plant\",\n","               \"Sheep\", \"Sofa\", \"Train\", \"Tvmonitor\", \"Total\",\n","              ]\n","\n","# Creamos el diccionario de clases\n","class_dict = dict(zip(range(len(class_names)), class_names))"],"metadata":{"id":"x1wMI7ecaPoz","executionInfo":{"status":"ok","timestamp":1717081041207,"user_tz":180,"elapsed":427,"user":{"displayName":"Waldo Hasperué","userId":"00409436718636391100"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Archivo con la imagen a analizar\n","image_file = \"test.jpg\""],"metadata":{"id":"RAR2Jo-q_90H","executionInfo":{"status":"ok","timestamp":1717081044722,"user_tz":180,"elapsed":327,"user":{"displayName":"Waldo Hasperué","userId":"00409436718636391100"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Cargamos la imagen a analizar\n","\n","image = keras.utils.load_img(image_file)\n","image = np.array(image)\n","\n","visualization.plot_image_gallery(\n","    np.array([image]),\n","    value_range=(0, 255),\n","    rows=1,\n","    cols=1,\n","    scale=5,\n",")\n","\n","# Preparamos la imagen para el modelo\n","inference_resizing = keras_cv.layers.Resizing(640, 640, pad_to_aspect_ratio=True, bounding_box_format=\"xywh\")\n","\n","image_mod = inference_resizing([image])"],"metadata":{"id":"36zdGQ_Tb89q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Configuración del algoritmo de NonMaxSuppression\n","prediction_decoder = keras_cv.layers.NonMaxSuppression(\n","    bounding_box_format=\"xywh\",\n","    from_logits=True,\n","    iou_threshold=0.3,          # Al usar un valor de 1 me quedo con todos los BB encontrados, dos BB no van a tener un IoU=1 a menos que sean el mismo\n","    confidence_threshold=0.7    # Al usar confianza en 0 me quedo con todos los BB encontrados\n",")\n","\n","# Creamos el modelo\n","model = keras_cv.models.YOLOV8Detector.from_preset(pretrained_model_name, bounding_box_format=\"xywh\",\n","                                                   prediction_decoder=prediction_decoder)"],"metadata":{"id":"x90fgW4VcEUp","executionInfo":{"status":"ok","timestamp":1717081874320,"user_tz":180,"elapsed":8688,"user":{"displayName":"Waldo Hasperué","userId":"00409436718636391100"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Hacer la predicción\n","\n","y_pred = model.predict(image_mod) # y_pred es un diccionario:\n","                                  # {\"classes\": ...,        # matriz con las clases de los objetos\n","                                  #  \"boxes\": ...,          # tensor con los bounding boxes\n","                                  #  \"confidence\": ...,     # matriz con las confianzas\n","                                  #  \"num_detections\": ...  # lista con la cantidad de objetos detectados\n","                                  #  }\n","\n","visualization.plot_bounding_box_gallery(\n","    image_mod,\n","    value_range=(0, 255),\n","    rows=1,\n","    cols=1,\n","    y_pred=y_pred,\n","    scale=5,\n","    font_scale=0.7,\n","    bounding_box_format=\"xywh\",\n","    class_mapping=class_dict,\n",")"],"metadata":{"id":"offKbW3geN-L"},"execution_count":null,"outputs":[]}]}