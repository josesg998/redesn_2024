{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade keras-cv"
      ],
      "metadata": {
        "id": "L7tWCefEvIGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import keras_cv\n",
        "from keras_cv import visualization"
      ],
      "metadata": {
        "id": "ku7dkuiHR88V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset a usar para entrenar\n",
        "\n",
        "# Rutas a los directorios con las imágenes y con las anotaciones de los bounding boxes\n",
        "# Por cada archivo con una imagen en el directorio de imágenes, tiene que haber otro con el mismo nombre\n",
        "# en el directorio labels, el cual contiene los bounding box presentes en la imagen.\n",
        "# Ejemplo: \"Perro.jpg\" en imágenes y \"Perro.txt\" en labels.\n",
        "\n",
        "path_images = \"./small/images/\"\n",
        "path_labels = \"./small/labels/\"\n",
        "\n",
        "# Archivo con los nombres de clases\n",
        "class_name_file = \"classes_names.txt\"\n",
        "\n",
        "# Extensión de archivo de las imágenes, si son más de una se pueden poner en una tupla. Ejemplo (\".jpg\", \".png\", \".bmp\")\n",
        "image_file_extension = \".jpg\"\n",
        "\n",
        "# Extensión de archivo de las anotaciones, si son más de una se pueden poner en una tupla. Ejemplo (\".txt\", \".xml\", \".json\")\n",
        "label_file_extension = \".txt\"\n",
        "\n",
        "# Formato de las anotaciones:\n",
        "# Más formatos en https://keras.io/api/keras_cv/bounding_box/\n",
        "bb_format = \"rel_xywh\"\n",
        "\n",
        "# Proporción de muestras para el dataset de entrenamiento\n",
        "SPLIT_RATIO = 0.7\n",
        "\n",
        "# Tamaño del batch\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "# Velocidad de aprendizaje\n",
        "LEARNING_RATE = 0.001"
      ],
      "metadata": {
        "id": "MEcXicxdL3NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Leemos las clases de objetos a detectar\n",
        "\n",
        "file_classes_names = open(class_name_file)\n",
        "classes_names = []\n",
        "for l in file_classes_names:\n",
        "  classes_names.append(l.strip())\n",
        "file_classes_names.close()\n",
        "\n",
        "class_dict = dict(zip(range(len(classes_names)), classes_names))\n",
        "\n",
        "pprint.pprint(class_dict)"
      ],
      "metadata": {
        "id": "sXF9vHKu289v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Leemos los archivos de imágenes y sus anotaciones\n",
        "\n",
        "labels_files = sorted(\n",
        "    [\n",
        "        os.path.join(path_labels, file_name)\n",
        "        for file_name in os.listdir(path_labels)\n",
        "        if file_name.endswith(label_file_extension)\n",
        "    ]\n",
        ")\n",
        "\n",
        "images_files = sorted(\n",
        "    [\n",
        "        os.path.join(path_images, file_name)\n",
        "        for file_name in os.listdir(path_images)\n",
        "        if file_name.endswith(image_file_extension)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "opzcbZClMq-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Leemos la información de las anotaciones\n",
        "\n",
        "def parse_annotation(fn):\n",
        "  if fn.endswith(\".txt\"):\n",
        "    # El archivo debe tener todas las anotaciones que posea la imagen correspondiente,\n",
        "    # y todas tienen que tener el mismo formato\n",
        "\n",
        "    _file = open(fn)\n",
        "    boxes = []\n",
        "    class_ids = []\n",
        "    for l in _file:\n",
        "      data = l.strip().split(\" \")\n",
        "\n",
        "      class_ids.append(int(data[0]))\n",
        "\n",
        "      xmin = float(data[1])\n",
        "      ymin = float(data[2])\n",
        "      width = float(data[3])\n",
        "      height = float(data[4])\n",
        "      boxes.append([xmin, ymin, width, height])\n",
        "    _file.close()\n",
        "\n",
        "  else:\n",
        "    # Implementar la lectura desde otros archivos\n",
        "    pass\n",
        "\n",
        "  return boxes, class_ids\n",
        "\n",
        "image_paths = []\n",
        "bbox = []\n",
        "classes = []\n",
        "i = 0\n",
        "for l in labels_files:\n",
        "    boxes, class_ids = parse_annotation(l)\n",
        "    image_path = images_files[i]; i+= 1\n",
        "    image_paths.append(image_path)\n",
        "    bbox.append(boxes)\n",
        "    classes.append(class_ids)\n",
        "\n",
        "bbox = tf.ragged.constant(bbox)\n",
        "classes = tf.ragged.constant(classes)\n",
        "image_paths = tf.ragged.constant(image_paths)"
      ],
      "metadata": {
        "id": "XRF3EpH-SWrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construir el dataset\n",
        "data = tf.data.Dataset.from_tensor_slices((image_paths, classes, bbox))\n",
        "\n",
        "# Separar en train set y test set\n",
        "nsamples = int(len(labels_files) * SPLIT_RATIO)\n",
        "train_data = data.take(nsamples)\n",
        "test_data = data.skip(nsamples)\n",
        "\n",
        "# Leer las imágenes\n",
        "def load_dataset(image_path, classes, bbox):\n",
        "    image = tf.io.read_file(image_path)\n",
        "\n",
        "    # Si no son imágenes jpg entonces leerlas con la función correspondiente\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "\n",
        "    bounding_boxes = {\n",
        "        \"classes\": classes,\n",
        "        \"boxes\": bbox,\n",
        "    }\n",
        "    return {\"images\": tf.cast(image, tf.float32), \"bounding_boxes\": bounding_boxes}\n",
        "\n",
        "def dict_to_tuple(inputs):\n",
        "    return inputs[\"images\"], inputs[\"bounding_boxes\"]\n",
        "\n",
        "train_ds = train_data.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.shuffle(BATCH_SIZE * 4)\n",
        "train_ds = train_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "augmenter = keras.Sequential(\n",
        "    layers=[\n",
        "        keras_cv.layers.RandomFlip(mode=\"horizontal\", bounding_box_format=bb_format),\n",
        "        keras_cv.layers.RandomShear(\n",
        "            x_factor=0.2, y_factor=0.2, bounding_box_format=bb_format\n",
        "        ),\n",
        "        keras_cv.layers.JitteredResize(target_size=(640, 640), scale_factor=(0.75, 1.3), bounding_box_format=bb_format)\n",
        "    ]\n",
        ")\n",
        "train_ds = train_ds.map(augmenter, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "train_ds = train_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_ds = test_data.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.shuffle(BATCH_SIZE * 4)\n",
        "test_ds = test_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "resizing = keras_cv.layers.JitteredResize(target_size=(640, 640), scale_factor=(0.75, 1.3), bounding_box_format=bb_format)\n",
        "test_ds = test_ds.map(resizing, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "test_ds = test_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "jSMMyuuIeueK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizamos algunas imágenes del dataset\n",
        "\n",
        "def visualize_dataset(inputs, value_range, rows, cols, bounding_box_format):\n",
        "    inputs = next(iter(inputs.take(1)))\n",
        "    images, bounding_boxes = inputs[0], inputs[1]\n",
        "    visualization.plot_bounding_box_gallery(\n",
        "        images,\n",
        "        value_range=value_range,\n",
        "        rows=rows,\n",
        "        cols=cols,\n",
        "        y_true=bounding_boxes,\n",
        "        scale=5,\n",
        "        font_scale=0.7,\n",
        "        bounding_box_format=bounding_box_format,\n",
        "        class_mapping=class_dict\n",
        "    )\n",
        "\n",
        "visualize_dataset(train_ds, bounding_box_format=bb_format, value_range=(0, 255), rows=2, cols=2)\n",
        "\n",
        "visualize_dataset(test_ds, bounding_box_format=bb_format, value_range=(0, 255), rows=2, cols=2)"
      ],
      "metadata": {
        "id": "nAAwosblSjUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos un modelo preentrenado\n",
        "\n",
        "backbone = keras_cv.models.YOLOV8Backbone.from_preset(\"yolo_v8_s_backbone_coco\")\n",
        "yolo = keras_cv.models.YOLOV8Detector(\n",
        "    num_classes=len(class_dict),\n",
        "    bounding_box_format=bb_format,\n",
        "    backbone=backbone,\n",
        "    fpn_depth=1,\n",
        ")\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "\n",
        "yolo.compile(optimizer=optimizer, classification_loss=\"binary_crossentropy\", box_loss=\"ciou\")"
      ],
      "metadata": {
        "id": "jNJTVRWvhOJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo\n",
        "EPOCHS = 2\n",
        "\n",
        "yolo.fit(\n",
        "    train_ds,\n",
        "    validation_data=test_ds,\n",
        "    epochs=EPOCHS\n",
        ")"
      ],
      "metadata": {
        "id": "i3Rbg9_AvxEC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}