{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Kt9ZkWa9XtGW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sklearn.metrics\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Para descomprimir el archivo Neumonia.zip (Si se usa desde Colab)\n",
        "# Creará dos carpetas:\n",
        "#     \"test\"\n",
        "#     \"train\"\n",
        "\n",
        "!unzip \"Neumonia.zip\" -d \".\""
      ],
      "metadata": {
        "id": "JrtDutst8PF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parámetros del notebook\n",
        "\n",
        "# 224x244x3 (RGB) son las dimensiones que espera VGG16\n",
        "width = 224   # ancho de las imágenes necesario para la arquitectura elegida\n",
        "height = 224  # alto de las imágenes necesario para la arquitectura elegida\n",
        "d_in = (height, width, 3)  # Dimensión de las imágenes de entradas\n",
        "\n",
        "batch_size = 24  # Cantidad de imágenes por lote (para el entrenamiento)\n",
        "\n",
        "train_folderpath = \"train/\"   # Directorio donde están las imágenes que se usaran en el entrenamiento\n",
        "test_folderpath = \"test/\"     # Directorio donde están las imágenes que se usaran para la validación\n",
        "\n",
        "d_out = 1     # Son dos clases, pero usamos codificación binaria (una única neurona de salida)\n",
        "\n",
        "# Función de preprocesamiento de las imágenes (propia de cada arquitectura)\n",
        "preprocessing_function = keras.applications.vgg16.preprocess_input"
      ],
      "metadata": {
        "id": "cSHHrzKugIh2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generadores\n",
        "# El parámetro rescale se encarga de escalar los valores del rango [0..255] a [0..1]\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255, preprocessing_function=preprocessing_function)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255, preprocessing_function=preprocessing_function)\n",
        "\n",
        "print(\"Train data\")\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_folderpath, # directorio de donde cargar las imagenes (train)\n",
        "    target_size=(height, width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        "    )\n",
        "\n",
        "n_train = train_generator.samples\n",
        "\n",
        "print(\"\\n\\nTest data\")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_folderpath, # directorio de donde cargar las imagenes (test)\n",
        "    target_size=(height, width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False)\n",
        "\n",
        "n_test = test_generator.samples\n",
        "\n",
        "# Obtengo un diccionario donde \"key\" es el nombre de la clase (nombre del directorio) y \"value\" es el valor de la clase (0,1, etc.)\n",
        "class_dict = train_generator.class_indices\n",
        "print(\"\\n\\nCodificación de clases\")\n",
        "print(class_dict)\n",
        "\n",
        " # Construyo un diccionario donde \"key\" es el valor de la clase (0, 1, etc.) y \"value\" es el nombre de la clase (nombre del directorio)\n",
        "class_dict_inverse = {}\n",
        "for key in class_dict:\n",
        "    value = class_dict[key]\n",
        "    class_dict_inverse[value] = key"
      ],
      "metadata": {
        "id": "dW-Ow2t9YD4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el modelo preentrenado, puede usar cualquier arquitectura vista en clase, otra provista por keras o alguna otra creada por usted\n",
        "\n",
        "base_model = keras.applications.VGG16(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=d_in,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")\n",
        "\n",
        "# \"Congelo\" todas las capas del modelo original\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "# Utilizar salida del modelo como entrada a una nueva capa\n",
        "# Flatten\n",
        "output = keras.layers.Flatten()(base_model.output)\n",
        "# Dense de 4096\n",
        "output = keras.layers.Dense(4096, activation= 'tanh')(output)\n",
        "# Dense de 512\n",
        "output = keras.layers.Dense(512, activation= 'tanh')(output)\n",
        "# Nueva capa de salida\n",
        "output = keras.layers.Dense(d_out, activation=\"softmax\")(output)\n",
        "\n",
        "model = keras.Model(inputs = base_model.input, outputs=output)\n",
        "\n",
        "model.compile(\n",
        "  optimizer = keras.optimizers.SGD(learning_rate=0.01),\n",
        "  loss = 'binary_crossentropy', metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "keras.utils.plot_model(model)"
      ],
      "metadata": {
        "id": "7vuqcnIRYLDz"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo\n",
        "\n",
        "epochs = 5\n",
        "class_weight = { 0: 0.33,\n",
        "                 1: 0.66 }\n",
        "\n",
        "history = model.fit(train_generator, steps_per_epoch = n_train // batch_size,\n",
        "                    epochs = epochs,  validation_data = test_generator, class_weight=class_weight\n",
        "                    )"
      ],
      "metadata": {
        "id": "CBjZnwQzYSg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hacer las predicciones con el conjunto de validación\n",
        "\n",
        "test_generator.reset()\n",
        "results = model.predict(test_generator)"
      ],
      "metadata": {
        "id": "YQNXyIocFQJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprimo resultados individuales\n",
        "\n",
        "print('TRUE CLASS\\tPREDICTED CLASS\\tFILENAME')\n",
        "\n",
        "test_file_names = test_generator.filenames\n",
        "test_labels = test_generator.labels # clase de cada muestra de test\n",
        "\n",
        "preds = np.zeros(results.shape)\n",
        "aciertos = 0\n",
        "for index, pred in enumerate(results):\n",
        "    pred = np.round(pred)\n",
        "\n",
        "    if (pred == test_labels[index]):\n",
        "      aciertos = aciertos + 1\n",
        "\n",
        "    pred_index = pred[0]\n",
        "    pred_class = class_dict_inverse[pred_index]\n",
        "    true_class = class_dict_inverse[test_labels[i]]\n",
        "    file = test_file_names[i]\n",
        "    print(f'{true_class}\\t{pred_class}\\t{file}')\n",
        "\n",
        "print(f\"\\n\\n{aciertos} aciertos en {test_labels.shape[0]} muestras de test.\")\n",
        "print(f\"Accuracy: {float(aciertos)/test_labels.shape[0]}\")"
      ],
      "metadata": {
        "id": "o3q-KXgUikwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprimo la matriz de confusión\n",
        "\n",
        "sklearn.metrics.ConfusionMatrixDisplay.from_predictions(test_labels, preds)"
      ],
      "metadata": {
        "id": "Zswp4qdOi7hS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}