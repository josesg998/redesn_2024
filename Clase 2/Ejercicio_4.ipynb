{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0MTmgsYJvcs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un dataset con todas las imágenes de un directorio y escalarlas al ancho y alto necesario para la arquitectura elegida\n",
        "\n",
        "# Parámetros del notebook\n",
        "path = \"./test/\"     # El directorio donde se leeran las imágenes\n",
        "                           # El directorio a leer deberá contar con subdirectorios, uno para cada clase\n",
        "                           # que se desee validar\n",
        "                           # Ejemplo:\n",
        "                           # ./Test\n",
        "                           #     |------ Clase1\n",
        "                           #     |           |------ Imagen1.jpg\n",
        "                           #     |           |------ Imagen2.jpg\n",
        "                           #     |           |------ Imagen3.jpg\n",
        "                           #     |------ Clase2\n",
        "                           #                 |------ Imagen4.jpg\n",
        "                           #                 |------ Imagen5.jpg\n",
        "                           #                 |------ Imagen6.jpg\n",
        "\n",
        "augmented_path = \"./augmented/\" # El directorio donde almacenar las imágenes transformadas\n",
        "                                # Debe existir y estar vacío\n",
        "\n",
        "# 224x244x3 (RGB) son las dimensiones que espera VGG16\n",
        "width = 224   # ancho de las imágenes necesario para la arquitectura elegida\n",
        "height = 224  # alto de las imágenes necesario para la arquitectura elegida\n",
        "\n",
        "# Función de preprocesamiento de las imágenes (propia de cada arquitectura)\n",
        "preprocessing_function = keras.applications.vgg16.preprocess_input\n"
      ],
      "metadata": {
        "id": "5-_JWitXPy2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el \"cargador\" de imágenes\n",
        "# Elegir todas las transformaciones que se deseen\n",
        "\n",
        "datagen = ImageDataGenerator(preprocessing_function=preprocessing_function,\n",
        "                             # Rota la imagen en un ángulo al azar entre (0 y 45) en sentido horario\n",
        "                             rotation_range=45)"
      ],
      "metadata": {
        "id": "18s_9tbBKB5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size tiene un número alto para asegurarse que todas las imágenes entren en el mismo y único lote\n",
        "\n",
        "generator = datagen.flow_from_directory(path, target_size=(height, width),\n",
        "                                        save_to_dir=augmented_path, batch_size=9999)\n",
        "\n",
        "# Obtengo el único lote con todas las imágenes\n",
        "batch_images = next(generator)\n",
        "n_images = len(batch_images[0])\n",
        "\n",
        "# Lectura de los archivos con las imágenes transformadas\n",
        "modified_images = os.listdir(augmented_path)\n",
        "for i in range(len(modified_images)):\n",
        "  fn = modified_images[i]\n",
        "  fn = fn[1:]\n",
        "  uc = fn.find(\"_\")\n",
        "  if uc == 1:\n",
        "    fn = \"0\" + fn\n",
        "  modified_images[i] = fn\n",
        "modified_images.sort()\n",
        "for i in range(len(modified_images)):\n",
        "  fn = modified_images[i]\n",
        "  if fn[0] == \"0\":\n",
        "    fn = fn[1:]\n",
        "  modified_images[i] = \"_\" + fn\n",
        "\n",
        "# Obtener el listado de los archivos leidos\n",
        "file_names = generator.filenames\n",
        "\n",
        "# Cargar el nombre de las clases de ImageNet\n",
        "content = open(\"ImageNet.classes\").readlines()\n",
        "class_names = [line[9:].strip() for line in content]"
      ],
      "metadata": {
        "id": "nTwlpsKBoyqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el modelo preentrenado, puede usar cualquier arquitectura vista en clase, otra provista por keras o alguna otra creada por usted\n",
        "\n",
        "model = keras.applications.VGG16(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")\n",
        "model.summary()\n",
        "keras.utils.plot_model(model)"
      ],
      "metadata": {
        "id": "g0J6YIYTjJmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validación del conjunto de testeo\n",
        "# Usar el modelo cargado para hacer la predicción\n",
        "\n",
        "for i in range(n_images):\n",
        "  image = batch_images[0][i]\n",
        "  file_name = file_names[i]\n",
        "\n",
        "  x = np.expand_dims(image, axis=0)\n",
        "  results = model.predict(x, verbose=False)\n",
        "  pred = np.argmax(results, axis=1)\n",
        "  pred_class = class_names[pred[0]]\n",
        "\n",
        "  print(f'Class: {pred_class}\\tProb. of class = {results[0][pred[0]]}')\n",
        "\n",
        "  image = load_img(path + file_names[i],color_mode='rgb', target_size=(224, 224))\n",
        "  display(image)\n",
        "\n",
        "  image = load_img(augmented_path + modified_images[i],color_mode='rgb', target_size=(224, 224))\n",
        "  display(image)\n",
        "\n",
        "  print(\"-----------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "id": "DUnl4lcX7Et1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}